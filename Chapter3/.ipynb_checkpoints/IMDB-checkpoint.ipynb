{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode the comment sequence\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    res = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        # this following line will make the position which shows in sequence to 1 in res\n",
    "        res[i, sequence] = 1.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the sequence\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize and change the data type of train data\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what is cross entropy and why we pick it as loss funciton\n",
    "Cross entropy is a reasonable way for measuring how close or how far is our prediction probability to the target probability. More specific visit https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 4s 154us/step - loss: 0.4497 - acc: 0.8164 - val_loss: 0.3351 - val_acc: 0.8786\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 2s 96us/step - loss: 0.2552 - acc: 0.9094 - val_loss: 0.3166 - val_acc: 0.8709\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.1969 - acc: 0.9299 - val_loss: 0.2822 - val_acc: 0.8880\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.1669 - acc: 0.9408 - val_loss: 0.2946 - val_acc: 0.8832\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 3s 106us/step - loss: 0.1431 - acc: 0.9487 - val_loss: 0.3228 - val_acc: 0.8784\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 2s 98us/step - loss: 0.1266 - acc: 0.9561 - val_loss: 0.3477 - val_acc: 0.8730\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 2s 87us/step - loss: 0.1128 - acc: 0.9610 - val_loss: 0.3613 - val_acc: 0.8713\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 2s 91us/step - loss: 0.1010 - acc: 0.9653 - val_loss: 0.4096 - val_acc: 0.8636\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 2s 89us/step - loss: 0.0903 - acc: 0.9686 - val_loss: 0.4175 - val_acc: 0.8649\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 2s 87us/step - loss: 0.0810 - acc: 0.9722 - val_loss: 0.4482 - val_acc: 0.8622\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 2s 87us/step - loss: 0.0737 - acc: 0.9756 - val_loss: 0.4742 - val_acc: 0.8610\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 2s 87us/step - loss: 0.0646 - acc: 0.9792 - val_loss: 0.5289 - val_acc: 0.8571\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.0604 - acc: 0.9794 - val_loss: 0.5297 - val_acc: 0.8594\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.0501 - acc: 0.9844 - val_loss: 0.5766 - val_acc: 0.8529\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.0472 - acc: 0.9850 - val_loss: 0.6081 - val_acc: 0.8537\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.0401 - acc: 0.9882 - val_loss: 0.6610 - val_acc: 0.8491\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 2s 88us/step - loss: 0.0364 - acc: 0.9890 - val_loss: 0.6835 - val_acc: 0.8504\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 2s 87us/step - loss: 0.0294 - acc: 0.9919 - val_loss: 0.7247 - val_acc: 0.8486\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.0265 - acc: 0.9925 - val_loss: 0.7411 - val_acc: 0.8500\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 2s 86us/step - loss: 0.0258 - acc: 0.9926 - val_loss: 0.7797 - val_acc: 0.8492\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, batch_size=512, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
